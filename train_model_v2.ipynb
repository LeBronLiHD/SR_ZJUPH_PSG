{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "049f8d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "DISABLE_GPU = True\n",
    "if DISABLE_GPU:\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfcb1fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import params\n",
    "import data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6b416c0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load .edf -> .\\data\\PSGData1_Hang7\\20190917-T3-93135.edf\n",
      "Extracting EDF parameters from E:\\ZJU_Research\\SR_ZJUPH_PSG\\data\\PSGData1_Hang7\\20190917-T3-93135.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ZJU_Research\\SR_ZJUPH_PSG\\utils.py:27: RuntimeWarning: Physical range is not defined in following channels:\n",
      "Thor, Abdo\n",
      "  raw_train = mne.io.read_raw_edf(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1186 36441088\n",
      "Normalizing ... Current Dimension -> 0\n",
      "Normalizing ... Current Dimension -> 1\n",
      "Normalizing ... Current Dimension -> 2\n",
      "Normalizing ... Current Dimension -> 3\n",
      "Normalizing ... Current Dimension -> 4\n",
      "Normalizing ... Current Dimension -> 5\n",
      "Normalizing ... Current Dimension -> 6\n",
      "Normalizing ... Current Dimension -> 7\n",
      "Normalizing ... Current Dimension -> 8\n",
      "Normalizing ... Current Dimension -> 9\n",
      "Normalizing ... Current Dimension -> 10\n",
      "Normalizing ... Current Dimension -> 11\n",
      "Normalizing ... Current Dimension -> 12\n",
      "Normalizing ... Current Dimension -> 13\n",
      "Normalizing ... Current Dimension -> 14\n",
      "Normalizing ... Current Dimension -> 15\n",
      "Normalizing ... Current Dimension -> 16\n",
      "Normalizing ... Current Dimension -> 17\n",
      "Normalizing ... Current Dimension -> 18\n",
      "Normalizing ... Current Dimension -> 19\n",
      "Normalizing ... Current Dimension -> 20\n",
      "Return data, np.std(data) is too Low! len data -> 36441088\n",
      "Normalizing ... Current Dimension -> 21\n",
      "Normalizing ... Current Dimension -> 22\n",
      "Return data, np.std(data) is too Low! len data -> 36441088\n",
      "Normalization Done!\n",
      "Generating Train&Test ... Current Index -> 0\n",
      "Generating Train&Test ... Current Index -> 50\n",
      "Generating Train&Test ... Current Index -> 100\n",
      "Generating Train&Test ... Current Index -> 150\n",
      "Generating Train&Test ... Current Index -> 200\n",
      "Generating Train&Test ... Current Index -> 250\n",
      "Generating Train&Test ... Current Index -> 300\n",
      "Generating Train&Test ... Current Index -> 350\n",
      "Generating Train&Test ... Current Index -> 400\n",
      "Generating Train&Test ... Current Index -> 450\n",
      "Generating Train&Test ... Current Index -> 500\n",
      "Generating Train&Test ... Current Index -> 550\n",
      "Generating Train&Test ... Current Index -> 600\n",
      "Generating Train&Test ... Current Index -> 650\n",
      "Generating Train&Test ... Current Index -> 700\n",
      "Generating Train&Test ... Current Index -> 750\n",
      "Generating Train&Test ... Current Index -> 800\n",
      "Generating Train&Test ... Current Index -> 850\n",
      "Generating Train&Test ... Current Index -> 900\n",
      "Generating Train&Test ... Current Index -> 950\n",
      "Generating Train&Test ... Current Index -> 1000\n",
      "Generating Train&Test ... Current Index -> 1050\n",
      "Generating Train&Test ... Current Index -> 1100\n",
      "Generating Train&Test ... Current Index -> 1150\n",
      "x_train -> (948, 30726, 23) (30726, 23)\n",
      "y_train -> (948,)\n",
      "x_test  -> (238, 30726, 23) (30726, 23)\n",
      "y_test  -> (238,)\n"
     ]
    }
   ],
   "source": [
    "x_train_ori, y_train_ori, x_test_ori, y_test_ori = data_loader.get_train_test_v2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6163772a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: visualkeras in d:\\miniconda3\\envs\\dl\\lib\\site-packages (0.0.2)\n",
      "Requirement already satisfied: numpy>=1.18.1 in d:\\miniconda3\\envs\\dl\\lib\\site-packages (from visualkeras) (1.21.5)\n",
      "Requirement already satisfied: aggdraw>=1.3.11 in d:\\miniconda3\\envs\\dl\\lib\\site-packages (from visualkeras) (1.3.14)\n",
      "Requirement already satisfied: pillow>=6.2.0 in d:\\miniconda3\\envs\\dl\\lib\\site-packages (from visualkeras) (9.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install visualkeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37ab4120",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: D:\\Miniconda3\\envs\\dl\n",
      "\n",
      "  added / updated specs:\n",
      "    - ann\n",
      "\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  ca-certificates    anaconda::ca-certificates-2022.4.26-h~ --> conda-forge::ca-certificates-2022.5.18.1-h5b45459_0\n",
      "  certifi            anaconda::certifi-2021.10.8-py39haa95~ --> conda-forge::certifi-2022.5.18.1-py39hcbf5309_0\n",
      "  openssl               anaconda::openssl-1.1.1n-h2bbff1b_0 --> conda-forge::openssl-1.1.1o-h8ffe710_0\n",
      "\n",
      "\n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n",
      "Rolling back transaction: ...working... done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR conda.core.link:_execute(730): An error occurred while installing package 'conda-forge::openssl-1.1.1o-h8ffe710_0'.\n",
      "\n",
      "[Errno 13] Permission denied: 'D:\\\\Miniconda3\\\\envs\\\\dl\\\\Library\\\\bin\\\\libssl-1_1-x64.dll'\n",
      "()\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: D:\\Miniconda3\\envs\\dl\n",
      "\n",
      "  added / updated specs:\n",
      "    - ann_visualizer\n",
      "\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  ca-certificates    anaconda::ca-certificates-2022.4.26-h~ --> conda-forge::ca-certificates-2022.5.18.1-h5b45459_0\n",
      "  certifi            anaconda::certifi-2021.10.8-py39haa95~ --> conda-forge::certifi-2022.5.18.1-py39hcbf5309_0\n",
      "  openssl               anaconda::openssl-1.1.1n-h2bbff1b_0 --> conda-forge::openssl-1.1.1o-h8ffe710_0\n",
      "\n",
      "\n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n",
      "Rolling back transaction: ...working... done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR conda.core.link:_execute(730): An error occurred while installing package 'conda-forge::openssl-1.1.1o-h8ffe710_0'.\n",
      "\n",
      "[Errno 13] Permission denied: 'D:\\\\Miniconda3\\\\envs\\\\dl\\\\Library\\\\bin\\\\libssl-1_1-x64.dll'\n",
      "()\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: D:\\Miniconda3\\envs\\dl\n",
      "\n",
      "  added / updated specs:\n",
      "    - graphviz\n",
      "\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  certifi            anaconda::certifi-2021.10.8-py39haa95~ --> pkgs/main::certifi-2022.5.18.1-py39haa95532_0\n",
      "  openssl               anaconda::openssl-1.1.1n-h2bbff1b_0 --> pkgs/main::openssl-1.1.1o-h2bbff1b_0\n",
      "\n",
      "The following packages will be SUPERSEDED by a higher-priority channel:\n",
      "\n",
      "  ca-certificates                                  anaconda --> pkgs/main\n",
      "\n",
      "\n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n",
      "Rolling back transaction: ...working... done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR conda.core.link:_execute(730): An error occurred while installing package 'defaults::openssl-1.1.1o-h2bbff1b_0'.\n",
      "\n",
      "[Errno 13] Permission denied: 'D:\\\\Miniconda3\\\\envs\\\\dl\\\\Library\\\\bin\\\\libssl-1_1-x64.dll'\n",
      "()\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda install -c conda-forge ann -y\n",
    "!conda install -c conda-forge ann_visualizer -y\n",
    "!conda install graphviz -y\n",
    "!conda install -c anaconda python-graphviz -y\n",
    "!conda install -c anaconda pydot -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae390c32",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 34.7 GiB for an array with shape (941, 7, 30726, 23) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# x_train = x_train_ori.reshape((x_train_ori.shape[0], x_train_ori.shape[1], x_train_ori.shape[2], 1))\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# x_test = x_test_ori.reshape((x_test_ori.shape[0], x_test_ori.shape[1], x_test_ori.shape[2], 1))\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# y_train, y_test = y_train_ori, y_test_ori\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m to_categorical\n\u001b[1;32m----> 5\u001b[0m x_train, y_train, x_test, y_test \u001b[38;5;241m=\u001b[39m \u001b[43mdata_loader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_sequence\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train_ori\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_categorical\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_train_ori\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mNUM_CLASS\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m                                                                 \u001b[49m\u001b[43mx_test_ori\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_categorical\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test_ori\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mNUM_CLASS\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mE:\\ZJU_Research\\SR_ZJUPH_PSG\\data_loader.py:97\u001b[0m, in \u001b[0;36mgenerate_sequence\u001b[1;34m(x_train, y_train, x_test, y_test)\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_sequence\u001b[39m(x_train, y_train, x_test, y_test):\n\u001b[1;32m---> 97\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_generate_sequence\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m)\u001b[49m, _generate_sequence(y_train), _generate_sequence(x_test), _generate_sequence(y_test)\n",
      "File \u001b[1;32mE:\\ZJU_Research\\SR_ZJUPH_PSG\\data_loader.py:94\u001b[0m, in \u001b[0;36m_generate_sequence\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m-\u001b[39m seq):\n\u001b[0;32m     93\u001b[0m     ret\u001b[38;5;241m.\u001b[39mappend(data[i:i\u001b[38;5;241m+\u001b[39mseq])\n\u001b[1;32m---> 94\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mret\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 34.7 GiB for an array with shape (941, 7, 30726, 23) and data type float64"
     ]
    }
   ],
   "source": [
    "# x_train = x_train_ori.reshape((x_train_ori.shape[0], x_train_ori.shape[1], x_train_ori.shape[2], 1))\n",
    "# x_test = x_test_ori.reshape((x_test_ori.shape[0], x_test_ori.shape[1], x_test_ori.shape[2], 1))\n",
    "# y_train, y_test = y_train_ori, y_test_ori\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "x_train, y_train, x_test, y_test = data_loader.generate_sequence(x_train_ori, to_categorical(y_train_ori, params.NUM_CLASS), \n",
    "                                                                 x_test_ori, to_categorical(y_test_ori, params.NUM_CLASS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd7d4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader.show_shape(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adefd356",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import cnn_1, cnn_2, cnn_lstm, cnn_crf, resnet_101v2, efficient_net_v2l, vgg_19\n",
    "import numpy as np\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.metrics import f1_score, accuracy_score, classification_report\n",
    "from glob import glob\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tqdm import tqdm\n",
    "from ann_visualizer.visualize import ann_viz\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import tensorboard\n",
    "import datetime\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import visualkeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06bc8dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_LIST = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2012cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_LIST.append(cnn_2())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7616034",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "MODEL_LIST.append(cnn_lstm())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438aec74",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_LIST.append(cnn_crf())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2852bb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME_LIST = [\"cnn_2\", \"cnn_lstm\", \"cnn_crf\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffe75e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "HIST_LIST, TRAINED_MODEL = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1813bea4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_model(MODEL_LIST[0], to_file=\"./images/\" + NAME_LIST[0] + \".png\", show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a630f090",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_model(MODEL_LIST[1], to_file=\"./images/\" + NAME_LIST[1] + \".png\", show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f43e9b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_model(MODEL_LIST[2], to_file=\"./images/\" + NAME_LIST[2] + \".png\", show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6640bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "DISABLE_GPU = False\n",
    "if DISABLE_GPU:\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f613b431",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_callbacks(file_path, model_name):\n",
    "    checkpoint = ModelCheckpoint(file_path, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "    early = EarlyStopping(monitor=\"val_acc\", mode=\"max\", patience=20, verbose=1)\n",
    "    redonplat = ReduceLROnPlateau(monitor=\"val_acc\", mode=\"max\", patience=5, verbose=2)\n",
    "    log_dir = \"logs/\" + str(model_name) + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    tfboard = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "    callbacks_list = [checkpoint, early, redonplat, tfboard]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07dada1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, name):\n",
    "    file_path = './models/' + name + \"_\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") + '.h5'\n",
    "    callbacks_list = get_callbacks(file_path, name)\n",
    "    opt = Adam(learning_rate=params.LEARNING_RATE)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    history = model.fit(x=x_train, y=y_train,\n",
    "                    epochs=params.EPOCH_NUM,\n",
    "                    batch_size=params.BATCH_SIZE,\n",
    "                    validation_data=(x_test, y_test),\n",
    "                    verbose=params.VERBOSE,\n",
    "                    callbacks=callbacks_list)\n",
    "    model = load_model(file_path)\n",
    "    test_loss, test_acc = model.evaluate((x_test, y_test), steps=len(y_test), verbose=1)\n",
    "    print('Loss: ', test_loss)\n",
    "    print('Accuracy: ', test_acc) \n",
    "    return history, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbaac142",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(MODEL_LIST)):\n",
    "    history, trained_model = train_model(MODEL_LIST[i], NAME_LIST[i])\n",
    "    HIST_LIST.append(history)\n",
    "    TRAINED_MODEL.append(trained_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2c446b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tr_plot(tr_data, start_epoch):\n",
    "    #Plot the training and validation data\n",
    "    tacc=tr_data.history['accuracy']\n",
    "    tloss=tr_data.history['loss']\n",
    "    vacc=tr_data.history['val_accuracy']\n",
    "    vloss=tr_data.history['val_loss']\n",
    "    Epoch_count=len(tacc)+ start_epoch\n",
    "    Epochs=[]\n",
    "    for i in range (start_epoch ,Epoch_count):\n",
    "        Epochs.append(i+1)   \n",
    "    index_loss=np.argmin(vloss)#  this is the epoch with the lowest validation loss\n",
    "    val_lowest=vloss[index_loss]\n",
    "    index_acc=np.argmax(vacc)\n",
    "    acc_highest=vacc[index_acc]\n",
    "    plt.style.use('fivethirtyeight')\n",
    "    sc_label='best epoch= '+ str(index_loss+1 +start_epoch)\n",
    "    vc_label='best epoch= '+ str(index_acc + 1+ start_epoch)\n",
    "    fig,axes=plt.subplots(nrows=1, ncols=2, figsize=(20,8))\n",
    "    axes[0].plot(Epochs,tloss, 'r', label='Training loss')\n",
    "    axes[0].plot(Epochs,vloss,'g',label='Validation loss' )\n",
    "    axes[0].scatter(index_loss+1 +start_epoch,val_lowest, s=150, c= 'blue', label=sc_label)\n",
    "    axes[0].set_title('Training and Validation Loss')\n",
    "    axes[0].set_xlabel('Epochs')\n",
    "    axes[0].set_ylabel('Loss')\n",
    "    axes[0].legend()\n",
    "    axes[1].plot (Epochs,tacc,'r',label= 'Training Accuracy')\n",
    "    axes[1].plot (Epochs,vacc,'g',label= 'Validation Accuracy')\n",
    "    axes[1].scatter(index_acc+1 +start_epoch,acc_highest, s=150, c= 'blue', label=vc_label)\n",
    "    axes[1].set_title('Training and Validation Accuracy')\n",
    "    axes[1].set_xlabel('Epochs')\n",
    "    axes[1].set_ylabel('Accuracy')\n",
    "    axes[1].legend()\n",
    "    plt.tight_layout    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4661267",
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix_plot(matrix, classes, name):\n",
    "    plt.figure(figsize=(12,10))\n",
    "    cmap = \"YlGnBu\"\n",
    "    ax= plt.subplot()\n",
    "    sns.heatmap(matrix, annot=True, fmt='g', ax=ax, cmap=cmap);  #annot=True to annotate cells, ftm='g' to disable scientific notation\n",
    "    plt.savefig('./images/' + name + 'con_mat.png')\n",
    "    # labels, title and ticks\n",
    "    ax.set_xlabel('Predicted labels');\n",
    "    ax.set_ylabel('True labels'); \n",
    "    ax.set_title('Confusion Matrix'); \n",
    "    ax.xaxis.set_ticklabels(classes); \n",
    "    ax.yaxis.set_ticklabels(classes[::-1]);\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382590d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_score(model, name, plot=True, labels=[0, 1, 2, 3, 4]):\n",
    "    matrix = confusion_matrix(predictions, labels)\n",
    "    print(matrix)\n",
    "    print('\\n')\n",
    "\n",
    "    f1 = f1_score(predictions, labels, average='weighted')\n",
    "    print(f'F1 Score: {f1}')\n",
    "    print('\\n')\n",
    "    \n",
    "    print(classification_report(predictions, labels, target_names=classes))\n",
    "    \n",
    "    if plot:\n",
    "        confusion_matrix_plot(matrix, labels, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3397185",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_and_f1(model, history, name):\n",
    "    cal_score(model, name, plot=True)\n",
    "    tr_plot(history, 0)\n",
    "    print(\"==\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c97bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(HIST_LIST)):\n",
    "    plot_and_f1(TRAINED_MODEL[i], HIST_LIST[i], NAME_LIST[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9336b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
